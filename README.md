# Wallet Chain Core

## Quick Start

```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
make setup
python src/main.py generate
```

PowerShell:
```powershell
$env:PRIVATE_KEY = "0xYOUR_PRIVATE_KEY"  # pragma: allowlist secret
make run
```

<details>
<summary><span style="font-size:1.25em"><strong>Week 1: Wallet + Chain</strong></span></summary>

Part 1 implements secure wallet management, canonical serialization, and base
types used across the project. A CLI wraps these features for quick testing.

## Getting Started

### Prerequisites
* **Python 3.14+**
* **Git**

### Installation
1. **Setup environment**:
```bash
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # macOS/Linux
```

2. **Install tools**:
```bash
make setup
```
`make setup` also writes a `.pth` file so `src/` is on `PYTHONPATH` (enables
`python -m pricing.*`, `from chain...`, `from core...` without extra setup).

### IDE setup (important)
Mark `src/` as a **Sources Root** so imports like `from core...` and
`from chain...` resolve correctly.



## Development Tools

* **Formatter**: `black` & `isort`
* **Linter**: `flake8`
* **Tests**: `pytest`
* **Security**: `detect-secrets`

## Commands

Use the following `make` commands for a standardized workflow:

| Command | Description |
| --- | --- |
| `make run` | Executes the main application (`src/main.py`) |
| `make test` | Runs the full `pytest` suite |
| `make check` | Runs the full suite: formatting (black/isort), linting (flake8), and tests |
| `make setup` | Installs dependencies and sets up pre-commit hooks |

## Project Structure

```
src/
  core/
    wallet_manager.py   # key management + signing
    serializer.py       # canonical JSON + keccak hashing
    base_types.py       # Address, TokenAmount, Transaction types
  chain/
    __init__.py         # chain module exports
    client.py           # RPC client with retries and error handling
    transaction_builder.py  # fluent transaction builder
    analyzer.py         # tx analysis CLI
  pricing/
    uniswap_v2_pair.py  # Uniswap V2 pair math + on-chain helpers
    route.py            # routing + gas-aware selection
    fork_simulator.py   # forked swap simulation
    mempool_monitor.py  # pending tx watcher
    impact_analyzer.py  # price impact CLI
  main.py               # CLI entrypoint
docs/
  examples/             # sample JSON payloads for CLI
```

## Part 1: WalletManager CLI

The CLI is in `src/main.py` and is used by `make run`. Wallet logic lives in
`src/core/wallet_manager.py`. The `chain/` module is reserved for transaction
building, sending, and analysis.

### Environment setup

The default commands read the private key from `PRIVATE_KEY`:

PowerShell:
```powershell
$env:PRIVATE_KEY = "0xYOUR_PRIVATE_KEY"  # pragma: allowlist secret
```

macOS/Linux:
```bash
export PRIVATE_KEY="0xYOUR_PRIVATE_KEY"  # pragma: allowlist secret
```

### Run

Default command prints the address from `PRIVATE_KEY`:
```bash
make run
```

You can also call the CLI directly with subcommands:
```bash
python src/main.py address
python src/main.py generate
python src/main.py sign-message "hello"
```

### Canonical serialization

`CanonicalSerializer` produces deterministic JSON and its keccak hash.
Rules:
- Keys sorted (recursive)
- No whitespace
- Unicode preserved (UTF-8)
- Floats rejected (use strings/integers)

Use the CLI:
```bash
python src/main.py serialize --input docs/examples/payload.json
python src/main.py hash --input docs/examples/payload.json
python src/main.py verify-determinism --input docs/examples/payload.json --iterations 50
```

### Base types

`Address` validates and normalizes to checksum (case-insensitive equality).
`TokenAmount` stores raw integer (wei) and uses `Decimal` for human values.
`TransactionRequest` produces a web3-compatible dict.
`TransactionReceipt` parses a receipt and computes tx fee.

### Transaction input validation

`sign-transaction` validates inputs early with clear errors:
- Required fields: `nonce`, `gas`, `value`, `data`, `chainId`
- Fee: either `gasPrice` **or** both `maxFeePerGas` and `maxPriorityFeePerGas`
- `to` is checksummed (or `null` for contract creation)
- Numeric fields accept `int` or `0x...` hex string

### Typed data signing (EIP-712)

Provide JSON files for domain, types, and value:
```bash
python src/main.py sign-typed-data --domain docs/examples/domain.json --types docs/examples/types.json --value docs/examples/value.json
```

### Transaction signing

Provide a JSON file containing the transaction dict:
```bash
python src/main.py sign-transaction --tx docs/examples/tx.json
```

### Base types helpers

Build a transaction dict from a type-safe spec (uses `Address` + `TokenAmount`):
```bash
python src/main.py build-transaction --input docs/examples/tx_spec.json
```

Example `tx_spec.json`:
```json
{
  "to": "0x000000000000000000000000000000000000dead",
  "value_human": "1.5",
  "decimals": 18,
  "symbol": "ETH",
  "data": "0x",
  "nonce": 1,
  "gas_limit": 21000,
  "max_fee_per_gas": 1000000000,
  "max_priority_fee": 100000000,
  "chain_id": 1
}
```

Compute fee from a receipt (uses `TransactionReceipt` + `TokenAmount`):
```bash
python src/main.py receipt-fee --input docs/examples/receipt.json
```

### Encrypted keyfile import/export

Export from `PRIVATE_KEY`:
```bash
python src/main.py keyfile-export --path wallet.json --password "strong-password"
```

Import and print address:
```bash
python src/main.py keyfile-import --path wallet.json --password "strong-password"
```

### Examples directory

All sample payloads are under `docs/examples/`:
- `domain.json`, `types.json`, `value.json` (EIP-712)
- `tx.json` (transaction signing)
- `payload.json` (canonical serialization)
- `tx_spec.json` (base types transaction builder)
- `receipt.json` (fee calculation)

### Tests

Run all tests:
```bash
make test
```

Run formatting, linting, and tests:
```bash
make check
```

## Part 2: Chain Module

### RPC Client

`ChainClient` provides resilient JSON-RPC calls with retries, backoff, and
endpoint fallback. It classifies common errors (insufficient funds, nonce too
low, replacement underpriced) and exposes helpers for balance, nonce, gas price,
estimate gas, send transaction, and receipts.

Example:
```python
from chain import ChainClient
from core.base_types import Address

client = ChainClient(["https://rpc.example"])
balance = client.get_balance(Address.from_string("0x000000000000000000000000000000000000dead"))
nonce = client.get_nonce(Address.from_string("0x000000000000000000000000000000000000dead"))
```

### GasPrice

`GasPrice` wraps base/priority fees and computes `maxFeePerGas` with a buffer:
```python
gas = client.get_gas_price()
max_fee = gas.get_max_fee("high")
```

### Transaction Builder

Fluent builder that composes a `TransactionRequest`, estimates gas, sets fees,
signs, and sends.

```python
from chain import TransactionBuilder
from core.base_types import Address, TokenAmount

tx = (
    TransactionBuilder(client, wallet)
    .to(Address.from_string("0x000000000000000000000000000000000000dead"))
    .value(TokenAmount.from_human("0.1", 18, "ETH"))
    .data(b"")
    .with_gas_estimate()
    .with_gas_price("high")
    .build()
)
```

To send:
```python
tx_hash = (
    TransactionBuilder(client, wallet)
    .to(Address.from_string("0x000000000000000000000000000000000000dead"))
    .value(TokenAmount.from_human("0.1", 18, "ETH"))
    .data(b"")
    .with_gas_estimate()
    .with_gas_price("medium")
    .send()
)
```

### Transaction Analyzer CLI (Optional)

Analyze any transaction:
```bash
python -m chain.analyzer <tx_hash> --rpc <URL>
python -m chain.analyzer <tx_hash> --rpc <URL> --format json
```

Features:
- Function decoding for common ERC-20/Uniswap calls
- Transfer/Swap/Sync event parsing
- Pending tx handling, invalid hash checks
- Revert reason (when available)
- Token metadata caching

## Part 3: Integration Test

Run the Sepolia integration test end-to-end:
```bash
SEPOLIA_RPC_URL=... RECIPIENT_ADDRESS=0x... PRIVATE_KEY=0x... python scripts/integration_test.py
```

Expected flow:
- Loads wallet from `PRIVATE_KEY`
- Connects to Sepolia
- Checks balance
- Builds an ETH transfer
- Estimates gas and sets fees
- Signs and verifies signature locally
- Sends transaction and waits for receipt
- Prints receipt analysis and PASS/FAIL

## Acceptance Checklist

Required:
- [x] `WalletManager` loads key from env, signs messages and transactions
- [x] Private key never appears in logs/repr/str (tested)
- [x] `CanonicalSerializer` deterministic over 1000 iterations
- [x] `Address` and `TokenAmount` with full validation
- [x] `ChainClient` connects, gets balance, estimates gas, sends transactions
- [x] `TransactionBuilder` creates and signs valid transactions
- [x] Transaction Analyzer CLI works on mainnet txs
- [x] Integration test passes on Sepolia (requires RPC + funded key)
- [x] Minimum 15 unit tests covering edge cases (37 tests)
- [x] README with setup and usage examples

Test coverage:
- [x] Wallet: key security, signing, verification
- [x] Serializer: all listed edge cases
- [x] Types: validation, arithmetic, equality
- [x] Client: retry logic, error classification
- [x] Builder: validation, gas estimation
- [x] Analyzer: parsing, decoding, edge cases

</details>
<details>
<summary><span style="font-size:1.25em"><strong>Week 2: Pricing</strong></span></summary>

### Overview
Pricing module for AMM math, routing, simulation, and mempool monitoring.

### Architecture
```
MempoolMonitor ──▶ ParsedSwap ──▶ PricingEngine ──┐
                                                   ├─▶ RouteFinder ──▶ Route
                                                   ├─▶ UniswapV2Pair (math)
                                                   └─▶ ForkSimulator (forked sim)
```

### Modules
- `src/pricing/uniswap_v2_pair.py`: Uniswap V2 pair math and helpers
- `src/pricing/route.py`: route modeling and route finding
- `src/pricing/fork_simulator.py`: swap/route simulation on forked RPC
- `src/pricing/mempool_monitor.py`: mempool swap parsing/monitoring
- `src/pricing/pricing_engine.py`: orchestration entry point
- `src/pricing/impact_analyzer.py`: price impact CLI
- `src/pricing/price_impact_analyzer.py`: price impact math utilities

### Setup
Start a local fork (requires Foundry/Anvil):
```bash
export ETH_RPC_URL="https://mainnet.example"
bash scripts/start_fork.sh
```
Install Foundry (Git Bash):
```bash
curl -L https://foundry.paradigm.xyz | bash
foundryup
```

Set RPC/WS endpoints (or copy from `env.example`):
```bash
export RPC_URL="https://mainnet.example"
export WS_URL="wss://mainnet.example"
```
Environment loading is centralized in `config.py`: all entrypoints call `config.get_env()` which loads `.env` once via `python-dotenv`. You can still export env vars, but `.env` works automatically.
For the mempool watcher script:
```bash
export WS_URL="wss://mainnet.example"
```
PowerShell convenience loader:
```powershell
.\scripts\load_env.ps1 -EnvFile .env
```

### Configuration
All entrypoints load environment variables via `config.get_env()` which lazily loads `.env` once. Prefer `config.get_env("NAME", required=True)` instead of `os.environ.get()` to keep configuration consistent and avoid leaking sensitive values in errors.

### Examples
```bash
python -m pricing.impact_analyzer 0xPairAddress --token-in USDC --sizes 1000,10000 --rpc $RPC_URL
```

```python
async def main():
    def on_swap(swap: ParsedSwap):
        print(f\"Detected swap: {swap.dex} {swap.method}\")
        print(f\"  {swap.amount_in} → min {swap.min_amount_out}\")
        print(f\"  Slippage tolerance: {swap.slippage_tolerance:.2%}\")

    monitor = MempoolMonitor(WS_URL, on_swap)
    await monitor.start()
```

```python
client = ChainClient([RPC_URL])
engine = PricingEngine(client, "http://127.0.0.1:8545", WS_URL)
engine.load_pools([Address.from_string("0xPairAddress")])
quote = engine.get_quote(token_in, token_out, amount_in, gas_price_gwei=10, sender=sender)
print(quote.expected_output, quote.simulated_output)
```

### Demo Runbook (Week 2)
1) Load env vars:
```powershell
.\scripts\load_env.ps1 -EnvFile .env
```

2) Start the fork (Git Bash):
```bash
export ETH_RPC_URL="https://mainnet.example"
bash scripts/start_fork.sh
```

3) Start mempool watcher (PowerShell):
```powershell
$env:WS_URL = "ws://127.0.0.1:8545"
python scripts/watch_mempool.py
```

4) Send a test swap on the fork (PowerShell):
```powershell
$env:ANVIL_SENDER = "0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266"
python scripts/send_test_swap.py
```

5) Show price impact table (mainnet pool):
```powershell
python -m pricing.impact_analyzer `
  0xB4e16d0168e52d35CaCD2c6185b44281Ec28C9Dc `
  --token-in USDC `
  --sizes 1000,10000,100000 `
  --rpc $env:RPC_URL
```

6) Show best route with gas flip:
```powershell
python scripts/demo_route.py
```

7) Show Solidity-matching math (tests):
```powershell
pytest tests/test_uniswap_v2_pair.py
```

### Tests
```bash
pytest tests/test_uniswap_v2_pair.py
pytest tests/test_route.py
pytest tests/test_price_impact_analyzer.py
pytest tests/test_mempool_monitor.py
pytest tests/test_mainnet_uniswap_v2_swap.py
```

### Checklist (Week 2)
- AMM math: integer-only, matches Solidity outputs
- Routing: multi-hop discovery with gas-aware selection
- Monitoring: pending tx watcher + swap decoding
- Simulation: forked swap execution + receipt parsing
- CLI: price impact analyzer output
- Docs: architecture + examples


</details>
<details>
<summary><span style="font-size:1.25em"><strong>Week 3: Exchange + Inventory</strong></span></summary>

### Overview
Week 3 integrates a CEX via `ccxt`, adds order book analytics, portfolio
tracking across venues, and PnL + rebalance planning for arbitrage workflows.

### Architecture
```
PricingEngine (Week 2) ──▶ ArbChecker ──▶ ExchangeClient (ccxt)
                                       ├─▶ OrderBookAnalyzer
                                       ├─▶ InventoryTracker
                                       └─▶ PnLEngine / RebalancePlanner
```

### Modules
- `src/exchange/client.py`: ccxt wrapper (order books, balances, orders, fees)
- `src/exchange/orderbook.py`: order book analytics and slippage modeling
- `src/inventory/tracker.py`: multi-venue inventory tracking
- `src/inventory/pnl.py`: arb trade PnL tracking and summaries
- `src/inventory/rebalancer.py`: rebalance planning (no execution)
- `src/integration/arb_checker.py`: end-to-end arb opportunity checks

### Architecture
```
┌──────────────┐     ┌─────────────────┐     ┌──────────────────────┐
│ Pricing      │────▶│ ArbChecker      │────▶│ InventoryTracker     │
│ (Uniswap V2) │     │ (decision core) │     │ + RebalancePlanner   │
└──────┬───────┘     └───────┬─────────┘     └──────────┬───────────┘
       │                     │                            │
       │                     │                            │
┌──────▼────────┐     ┌──────▼──────────┐        ┌────────▼─────────┐
│ ChainClient   │     │ ExchangeClient  │        │ PnLEngine         │
│ (RPC/tx)      │     │ (Binance)       │        │ (trades, charts)  │
└───────────────┘     └──────┬──────────┘        └──────────────────┘
                             │
                             │
                      ┌──────▼─────────┐
                      │ OrderBook      │
                      │ Analyzer + WS  │
                      └────────────────┘
```

### Setup
Set Binance testnet credentials (see `env.example`):
```powershell
$env:BINANCE_TESTNET_API_KEY = "your_key_here"
$env:BINANCE_TESTNET_SECRET = "your_secret_here"
```

`config.BINANCE_CONFIG` reads env vars via `config.get_env()` and enables the
Binance sandbox + rate limiting by default.

### CLIs (Quick Reference)
Live order book + analysis:
```bash
python -m src.exchange.orderbook ETH/USDT --depth 50 --depth-bps 15 --imbalance-levels 10 --walk-sizes 1,5,10
```

Live order book (WebSocket):
```bash
python -m src.exchange.orderbook_ws ETH/USDT --ws-mode stream
python -m src.exchange.orderbook_ws ETH/USDT --ws-mode api
```

Notes:
- For mainnet streams, the REST snapshot runs without testnet keys; if you want
  authenticated mainnet REST calls, set `BINANCE_API_KEY`/`BINANCE_SECRET`.
- For testnet streams, pass `--testnet` and set
  `BINANCE_TESTNET_API_KEY`/`BINANCE_TESTNET_SECRET`.
- Enable debug logs with `ORDERBOOK_WS_DEBUG=1`.

LIMIT IOC (testnet):
```bash
python scripts/demo_ioc.py --symbol ETH/USDT --amount 0.01 --price-multiplier 0.999
```

Portfolio snapshot (Binance + wallet):
```bash
python scripts/demo_snapshot.py --wallet-balances docs/examples/wallet_balances.json
```

Arb checker (real prices):
```bash
python -m src.integration.arb_checker ETH/USDT --size 1 --gas-usd 5 --balances docs/examples/wallet_balances.json
```

Arb checker (marginal-size optimization):
```bash
python -m src.integration.arb_checker ETH/USDT --size 2 --step 0.1 --gas-usd 5 --balances docs/examples/wallet_balances.json
```
Notes:
- Uses marginal slice pricing on DEX/CEX order books to find the optimal size.
- Stops when the next slice becomes unprofitable; gas is amortized across slices.
- DEX fee + price impact are already included in AMM execution prices.

PnL report (5 trades):
```bash
python -m src.inventory.pnl --summary --trades docs/examples/pnl_trades.json
```

Check inventory skew:
```bash
python -m src.inventory.rebalancer --check
```

Generate rebalance plan:
```bash
python -m src.inventory.rebalancer --plan ETH
```

Stretch goals

Real-time inventory dashboard (TUI):
```bash
python -m src.inventory.dashboard --interval 5 --wallet-balances docs/examples/wallet_balances.json --wallet-only --nonzero-only
```

Historical PnL chart export:
```bash
python -m src.inventory.pnl --export-chart pnl.png --trades docs/examples/pnl_trades.json
```

Arb check with CSV logging:
```bash
python -m src.integration.arb_checker ETH/USDT --size 1 --log-csv arb.csv --log-min-bps 0
```

### Definition of Done
## Required (all must pass)
- [x] `ExchangeClient` connects to Binance testnet and fetches order books
- [x] `ExchangeClient` places and cancels LIMIT IOC orders
- [x] Rate limiter prevents API ban
- [x] `OrderBookAnalyzer.walk_the_book` simulates fills correctly
- [x] `OrderBookAnalyzer` CLI shows depth, spread, imbalance
- [x] `InventoryTracker` aggregates balances across venues
- [x] `InventoryTracker.can_execute` validates both legs before trade
- [x] `InventoryTracker.skew` detects imbalanced positions
- [x] `RebalancePlanner` generates valid transfer plans
- [x] `RebalancePlanner` respects min operating balances
- [x] `PnLEngine` tracks per-trade and aggregate PnL correctly
- [x] `ArbChecker` integrates pricing (Week 2) + exchange + inventory
- [x] Minimum 25 tests covering edge cases (current: 70+ unit tests)
- [x] README with architecture diagram showing module interactions

## Tests Must Cover
- [x] Order book parsing with real testnet data (live integration test, skipped without keys)
- [x] Walk-the-book with various sizes (small, large, insufficient)
- [x] Inventory update after trades (buy/sell/fee deductions)
- [x] Skew calculation with various distributions
- [x] Rebalance plan generation with fee accounting
- [x] PnL calculation with real fee structures
- [x] Integration: arb check passes when profitable, rejects when not

## Stretch Goals
- [x] WebSocket-based order book with incremental updates (+10)
- [ ] Multi-exchange support (add Bybit testnet via ccxt) (+10)
- [x] Real-time inventory dashboard (terminal UI) (+5)
- [x] Historical PnL chart export (matplotlib/plotly) (+5)
- [x] Arb opportunity logger with CSV export (+5)

to be continued...
</details>
<details>
<summary><span style="font-size:1.25em"><strong>Week 4: Strategy + Execution + Recovery</strong></span></summary>

### Overview
Week 4 turns the system into a production-style arbitrage loop:
- strategy generates opportunities from CEX/DEX prices,
- scorer ranks them by quality,
- executor runs two-leg state-machine execution with retries/unwind,
- recovery layer protects against duplicates, stale signals, and cascading failures.

This week introduces the decision-and-control plane for reliable operation.

### Architecture
```
SignalGenerator ──▶ SignalScorer ──▶ SignalPriorityQueue ──▶ Executor
      │                    │                   │                 │
      │                    │                   │                 ├─▶ RecoveryManager
      │                    │                   │                 │    ├─ CircuitBreaker
      │                    │                   │                 │    ├─ ReplayProtection
      │                    │                   │                 │    └─ FailureClassifier
      │                    │                   │                 │
      └─ uses CEX+DEX prices ───────────────────────────────────┘
```

### Key Modules
- `src/strategy/signal.py`
  - `Signal` dataclass + `Direction` enum.
  - Built-in validity checks (`expiry`, inventory/limits, expected net PnL, score).
  - Unique `signal_id` and helper methods (`create`, `age_seconds`).

- `src/strategy/fees.py`
  - Fee model (`FeeStructure`) for CEX fee + DEX fee + slippage + gas.
  - Computes `total_fee_bps`, breakeven spread, and expected net profit.

- `src/strategy/generator.py`
  - Fetches CEX order book and DEX quote (real pricer when configured, otherwise fallback simulation).
  - Computes spread in both directions:
    - BUY CEX / SELL DEX
    - BUY DEX / SELL CEX
  - Applies profitability gates (`min_spread_bps`, `min_profit_usd`), cooldown, inventory checks, and position limits.
  - Emits a rich `Signal` with metadata (depth, breakeven bps, raw prices).

- `src/strategy/scorer.py`
  - Multi-factor scoring (0-100):
    - spread (optionally net-of-fees),
    - liquidity (top-of-book depth),
    - inventory impact (rebalancing vs worsening skew),
    - pair-specific history (EMA),
    - urgency/freshness.
  - Produces transparent score breakdown in `signal.meta["score_breakdown"]`.
  - Supports score decay over time for queue prioritization.

- `src/executor/engine.py`
  - Strict state machine with guarded transitions:
    - `IDLE -> VALIDATING -> LEG1_* -> LEG2_* -> DONE/FAILED/UNWINDING`
  - Supports DEX-first (Flashbots style) and CEX-first sequencing.
  - Retry with exponential backoff and per-leg timeout.
  - Unwind flow if first leg fills and second leg fails.
  - Tracks detailed execution metrics (latency, retries, slippage, fill ratio) and event audit trail.
  - Computes realized PnL from actual fills and fee assumptions.

- `src/executor/recovery.py`
  - `FailureClassifier`: categorizes errors (TRANSIENT, PERMANENT, RATE_LIMIT, NETWORK, UNKNOWN).
  - `CircuitBreaker`: global + per-pair breaker with failure-window and drawdown trip logic.
  - `ReplayProtection`: dedup, staleness checks, nonce monotonicity, bounded memory (LRU), audit log.
  - `RecoveryManager`: single pre-flight and post-outcome interface used by executor.

- `scripts/arb_bot.py`
  - Orchestrates end-to-end runtime loop:
    - signal generation,
    - scoring + queueing,
    - execution,
    - balance sync,
    - metrics and webhook integration,
    - recovery snapshots / breaker visibility.

### Runtime Flow
1. Load balances and market data.
2. Generate candidate signals per pair.
3. Score and filter by minimum score.
4. Push to priority queue and drain highest-priority first.
5. Execute via state machine (with retries and guarded transitions).
6. On failure, trigger unwind if needed and record outcome in recovery.
7. Update historical scorer outcomes and metrics.

### Configuration Highlights
- Strategy thresholds: `min_spread_bps`, `min_profit_usd`, `max_position_usd`, `signal_ttl_seconds`, `cooldown_seconds`.
- Scorer threshold: `min_score` (typically 50-60).
- Executor controls: `use_flashbots`, leg timeouts, retry counts, `simulation_mode`.
- Recovery controls:
  - breaker `failure_threshold`, `window_seconds`, `max_drawdown_usd`, `cooldown_seconds`,
  - replay `ttl_seconds`, `max_age_seconds`, `nonce_check`.

### Run
Both modes live in a single script — `scripts/arb_bot.py`:

```bash
# Simulation — fake DEX prices, frequent trades, full pipeline
python scripts/arb_bot.py --mode simulation

# Paper — REAL CEX + DEX on-chain prices, simulated execution, PnL dashboard
python scripts/arb_bot.py --mode paper
```

Default (no flag) is `simulation`.

### Tests (Week 4)
Main suites:
- `tests/test_signal.py`
- `tests/test_scorer.py`
- `tests/test_executor.py`
- `tests/test_recovery.py`

Run just Week 4 tests:
```bash
pytest tests/test_signal.py tests/test_scorer.py tests/test_executor.py tests/test_recovery.py
```

Run all:
```bash
make test
```

### Definition of Done (Week 4)
- [x] Signals include economics + validity gates
- [x] Generator validates spread/profit/inventory/limits
- [x] Scorer ranks opportunities with transparent breakdown
- [x] Executor enforces strict transition-safe state machine
- [x] Retry/backoff and unwind logic implemented
- [x] Recovery layer protects against replay/stale/duplicate signals
- [x] Circuit breaker trips on failures and drawdown
- [x] Comprehensive unit tests for signal/scorer/executor/recovery

### Stretch Goals
- [x] Webhook alerts on circuit breaker trip
- [x] Real DEX execution (not simulation)
- [x] Multiple signals queued by priority
- [x] Prometheus metrics export

---

### Stretch Goal 1 — Webhook Alerts on Circuit Breaker Trip ✅

**Module:** `src/executor/alerts.py`

**What's implemented:**
- `WebhookAlerter` with background delivery thread — fire-and-forget, never blocks the hot path.
- Alert types: `CIRCUIT_BREAKER_TRIP`, `CIRCUIT_BREAKER_HALF_OPEN`, `CIRCUIT_BREAKER_RESET`, `EXECUTION_FAILURE`, `DRAWDOWN`.
- `WebhookConfig.from_env()` reads `WEBHOOK_URLS`, `WEBHOOK_TIMEOUT`, `WEBHOOK_MAX_RETRIES`, `WEBHOOK_COOLDOWN` from `.env`.
- Per-alert-type + per-pair cooldown to avoid alert storms.
- Exponential back-off retry on failed deliveries.
- Bounded queue (500 max) — drops oldest if full.
- `RecoveryManager.record_outcome()` automatically fires `on_circuit_breaker_trip()` when breaker transitions from CLOSED → OPEN.
- `ArbBot._tick()` also fires `on_execution_failure()` on every failed execution.

**Integration in `scripts/arb_bot.py`:**
```python
self.alerter = WebhookAlerter(WebhookConfig.from_env())
self.alerter.start()
self.executor.recovery.alerter = self.alerter  # auto-fires on CB trip
```

**How to test:**
```bash
pytest tests/test_alerts.py -v
```
Tests cover: payload structure, env config parsing, disabled alerter, cooldown throttling, real HTTP delivery to a local test server, retry on 500, all-retries-fail tracking, convenience senders (`on_circuit_breaker_trip`, `on_circuit_breaker_half_open`, `on_circuit_breaker_reset`, `on_execution_failure`, `on_drawdown`), and stats structure.

**Manual smoke test:**
1. Set `WEBHOOK_URLS=https://your-endpoint.com/hook` in `.env`.
2. Run the bot and force repeated failures (e.g. misconfigure DEX config so every execution fails).
3. After `failure_threshold` failures within the window, the circuit breaker trips → webhook fires with a JSON payload containing `type`, `level`, `pair`, `message`, `details`, `timestamp`.

---

### Stretch Goal 2 — Real DEX Execution (Not Simulation) ✅

**Module:** `src/executor/engine.py` → `_execute_real_dex_leg()`

**What's implemented:**
- When `ExecutorConfig.simulation_mode = False`, the executor calls `_execute_real_dex_leg()` instead of returning a simulated fill.
- Builds and signs real Uniswap V2 swap transactions via `TransactionBuilder`:
  - `BUY_CEX_SELL_DEX` → `swapExactETHForTokens` (sell ETH for quote token on DEX).
  - `BUY_DEX_SELL_CEX` → `swapExactTokensForETH` (sell quote token for ETH on DEX).
- Configurable slippage (`dex_slippage_bps`), deadline (`dex_deadline_seconds`), gas priority (`dex_gas_priority`), and chain ID (`dex_chain_id`).
- Uses `ChainClient` for RPC and `WalletManager` for key management — initialized lazily via `_ensure_dex_ready()`.
- Returns real tx hash from on-chain receipt.
- Simulation path returns `0xsim_...` hashes; real path returns actual `0x...` hashes.

**Branching logic:**
```python
async def _execute_dex_leg(self, signal, size):
    if self.config.simulation_mode:
        return {"success": True, "price": ..., "tx_hash": "0xsim_..."}
    return await asyncio.to_thread(self._execute_real_dex_leg, signal, size)
```

**How to test:**
```bash
pytest tests/test_executor.py -v
```
The executor test suite covers the full state machine (IDLE → VALIDATING → LEG1 → LEG2 → DONE/FAILED/UNWINDING) in simulation mode. Real DEX execution is integration-level and requires a testnet setup.

**Manual smoke test (Sepolia testnet):**
1. Set in `.env`:
   ```
   SEPOLIA_RPC_URL=https://eth-sepolia.g.alchemy.com/v2/YOUR_KEY
   PRIVATE_KEY=0x...
   DEX_ROUTER_ADDRESS=0x...   # Uniswap V2 Router on Sepolia
   DEX_WETH_ADDRESS=0x...
   DEX_QUOTE_TOKEN_ADDRESS=0x...
   ```
2. Run `scripts/arb_bot.py` with `simulation=False` in config.
3. Confirm execution context has a real tx hash format (`0x...64hex`) instead of `0xsim_...`.
4. Verify transaction on Sepolia Etherscan.

---

### Stretch Goal 3 — Multiple Signals Queued by Priority ✅

**Module:** `src/strategy/priority_queue.py`

**What's implemented:**
- `SignalPriorityQueue` backed by a min-heap (negated scores for max-priority-first ordering).
- Configurable via `PriorityQueueConfig`:
  - `max_depth` (default 50) — evicts lowest-scoring signals when over capacity.
  - `max_per_pair` (default 1) — prevents executing 2 signals for the same pair in one tick.
  - `score_decay` — re-applies decay function before yielding (stale signals lose priority).
  - `min_score` — drops signals that fall below threshold after decay.
- Deduplication by `signal_id` — rejects duplicate pushes.
- `drain()` yields signals in descending score order with expiry checks.
- Stats tracking: `total_pushed`, `total_dropped`, `total_yielded`, `queued`.

**Integration in `scripts/arb_bot.py`:**
```python
# Phase 1: Collect signals into priority queue
self.priority_queue.clear()
for pair in self.pairs:
    signal = self.generator.generate(pair, self.trade_size)
    signal.score = self.scorer.score(signal, skews)
    self.priority_queue.push(signal)

# Phase 2: Execute signals in priority order
for signal in self.priority_queue.drain():
    ctx = await self.executor.execute(signal)
```

**How to test:**
```bash
pytest tests/test_priority_queue.py -v
```
Tests cover: push/drain ordering, deduplication, max-depth eviction with stats, per-pair concurrency limits, signal expiry, score decay application, decay-below-min-score drop, peek without removal, clear, and stats accumulation.

**Manual smoke test:**
1. Configure multiple pairs (e.g. `ETH/USDT`, `BTC/USDT`, `ARB/USDT`) in bot config.
2. Lower `min_score` to ~30 so multiple signals are accepted.
3. Run bot and observe logs — higher-score signals are executed first within each tick.
4. Confirm `arb_queue_depth` gauge in `/metrics` reflects queue size before draining.

---

### Stretch Goal 4 — Prometheus Metrics Export ✅

**Module:** `src/executor/metrics.py`

**What's implemented:**
- Custom Prometheus-compatible metrics (no `prometheus_client` dependency):
  - **Counter**: `arb_signals_total{pair,direction}`, `arb_executions_total{pair,state}`, `arb_unwinds_total{pair,success}`, `arb_circuit_breaker_trips_total{pair}`, `arb_webhook_sent_total`.
  - **Gauge**: `arb_spread_bps{pair}`, `arb_score{pair}`, `arb_pnl_total_usd`, `arb_inventory_skew_pct{pair,venue}`, `arb_circuit_breaker_state{pair}` (0=closed, 1=open, 2=half_open), `arb_queue_depth`.
  - **Histogram**: `arb_execution_latency_ms{pair,leg}` with configurable buckets.
- `MetricsRegistry` collects all metrics and emits Prometheus text exposition format.
- `MetricsServer` runs a background HTTP server (default port 9090):
  - `GET /metrics` — full Prometheus scrape endpoint.
  - `GET /health` — health check (`{"status":"ok"}`).
- Thread-safe counters and gauges (tested with concurrent writes).

**Integration in `scripts/arb_bot.py`:**
```python
self.metrics = MetricsRegistry()
self.metrics_server = MetricsServer(self.metrics, port=metrics_port)
self.metrics_server.start()

# In _tick():
self.metrics.signals_total.inc(pair=pair, direction=signal.direction.name)
self.metrics.spread_bps.set(signal.spread_bps, pair=pair)
self.metrics.pnl_total.inc(ctx.actual_net_pnl or 0)
self.metrics.queue_depth.set(self.priority_queue.size)
self.metrics.cb_state.set(cb_val, pair=pair)
```

**How to test:**
```bash
pytest tests/test_metrics.py -v
```
Tests cover: counter inc (with/without labels), gauge set/inc/overwrite, histogram observe with buckets and labels, HELP/TYPE header lines, registry `collect_all()` output, real HTTP `/metrics` endpoint, `/health` endpoint, 404 on unknown paths, server start/stop lifecycle, and concurrent thread-safety for counters and gauges.

**Manual smoke test:**
1. Start the bot (default `METRICS_PORT=9090`).
2. Open `http://localhost:9090/metrics` in a browser or `curl`.
3. Verify Prometheus text format with key series:
   ```
   # HELP arb_signals_total Total arbitrage signals generated
   # TYPE arb_signals_total counter
   arb_signals_total{pair="ETH/USDT",direction="BUY_CEX_SELL_DEX"} 5.0

   # HELP arb_pnl_total_usd Cumulative PnL in USD
   # TYPE arb_pnl_total_usd gauge
   arb_pnl_total_usd 12.5
   ```
4. Add to `prometheus.yml`:
   ```yaml
   scrape_configs:
     - job_name: 'arb-bot'
       static_configs:
         - targets: ['localhost:9090']
   ```

---

### Run All Stretch Goal Tests
```bash
pytest tests/test_alerts.py tests/test_priority_queue.py tests/test_metrics.py tests/test_executor.py -v
```
</details>
<details>
<summary><span style="font-size:1.25em"><strong>Week 5: Dry Run &amp; Micro-Arb Bot</strong></span></summary>

### Overview

Week 5 is about running the **full arbitrage stack in dry-run mode** with:

- a focused **Arbitrum ⇄ MEXC micro-arbitrage loop** (`DoubleLimitArbitrageEngine`),
- strict **safety limits** and **kill switch**,
- **structured logging**, **webhook alerts**, and an optional **Telegram bot**,
- and a repeatable **pre‑flight token verification** flow.

The goal is to behave like a production bot while **never placing real orders** yet.

---

### High-Level Architecture (Implemented)

#### Layer 1 — Infrastructure

Conceptually:

```
┌─────────────────────────────────────────┐
│  Arbitrum RPC (Alchemy or similar)     │
│  • Used by ChainClient + Uniswap V3    │
│  • Low-latency HTTPS RPC               │
└─────────────────┬──────────────────────┘
                  │
┌─────────────────▼──────────────────────┐
│  Wallet + Key Management               │
│  • WalletManager (signing, address)    │
│  • Capital limited to test size        │
└────────────────────────────────────────┘
```

In code:

- `ChainClient` (`src/chain/client.py`) uses `ARBITRUM_RPC_HTTPS`/`ARBITRUM_RPC_WSS` from `.env`.
- `WalletManager` (`src/core/wallet_manager.py`) holds the Arbitrum key when you enable on-chain V3 range orders.
- For micro-arb dry run, **no real on-chain trades are sent**; the engine uses ODOS quotes and MEXC order books only.

#### Layer 2 — Monitoring & Detection

Instead of external price feeds, Week 5 uses **direct venue data**:

```
┌─────────────────────────────────────────┐
│  MEXC REST API (spot)                  │
│  • get_order_book() top-of-book L2     │
│  • 0% maker-fee limit orders           │
└─────────────────┬──────────────────────┘
                  │
┌─────────────────▼──────────────────────┐
│  ODOS Aggregator (pricing.odos_client) │
│  • USDC → token quotes on Arbitrum     │
│  • Realistic DEX execution prices      │
└────────────────────────────────────────┘
```

In code:

- `scripts/demo_double_limit.py`:
  - pulls MEXC order books via `MexcClient.get_order_book()` (`src/exchange/mexc_client.py`),
  - pulls DEX quotes via `OdosClient.quote()` (`src/pricing/odos_client.py`),
  - loops every few seconds and logs spreads + **net** PnL for a curated token universe from `config_tokens_arb_mex.py`.

#### Layer 3 — Execution Engine (Double Limit)

Core micro-arb logic lives in `src/executor/double_limit_engine.py`:

```
┌─────────────────────────────────────────┐
│  DoubleLimitArbitrageEngine            │
│  • Evaluates CEX vs ODOS prices        │
│  • Models LP fee + gas + bridge costs  │
│  • Chooses direction (mex→arb / arb→mex)│
└─────────────────┬──────────────────────┘
                  │
        (Week 5: evaluation only)
```

- `evaluate_opportunity()`:
  - reads top-of-book from MEXC,
  - gets a $5 USDC → token ODOS quote,
  - computes:
    - gross spread,
    - LP fee (0.3% tier) + gas + amortized bridge cost via `CapitalManager`,
    - **net_profit_usd** and **net_profit_pct**,
    - whether the opportunity is `executable` under configured thresholds.
- In Week‑5 **dry run**, `demo_double_limit` only calls `evaluate_opportunity` and logs:
  - `spread=…% net=$… (%) EXECUTABLE/SKIP` — **no orders are sent**.

The full `execute_double_limit()` path exists (post-only MEXC + optional Uniswap V3 range orders via `UniswapV3RangeOrderManager`) but is not used in the dry-run script.

#### Layer 4 — Capital Management

Capital and bridging policy are encapsulated in `src/core/capital_manager.py`:

```
┌─────────────────────────────────────────┐
│  CapitalManager                         │
│  • Tracks trade_count_since_bridge      │
│  • Amortizes bridge cost over trades    │
│  • Decides when to bridge ≥ $20 profit  │
└─────────────────────────────────────────┘
```

- `CapitalManagerConfig` sets:
  - `starting_cex_usd`, `starting_chain_usd`,
  - `bridge_threshold_usd` (e.g. $20),
  - `bridge_fixed_cost_usd` (e.g. $0.05 — actual MEXC withdrawal fee for USDT on Arbitrum One).
- The Double Limit engine pulls an **amortized bridge cost per trade** from `get_effective_bridge_cost()`, so micro trades are only considered if they can dilute fixed costs.
- **Cost verification**: Run `python scripts/verify_all_costs.py` to verify gas costs, bridge fees, and LP fees match actual market conditions.

---

### Safety, Dry Run & Kill Switch

#### Absolute Safety Constants

`src/safety.py` defines **hard-coded, non-configurable** limits:

```python
ABSOLUTE_MAX_TRADE_USD = 25.0
ABSOLUTE_MAX_DAILY_LOSS = 20.0
ABSOLUTE_MIN_CAPITAL = 50.0
ABSOLUTE_MAX_TRADES_PER_HOUR = 30
```

and a final gate:

```python
def safety_check(trade_usd, daily_loss, total_capital, trades_this_hour) -> tuple[bool, str]:
    ...
```

`scripts/arb_bot.py` calls `safety_check(...)` **after all other checks** (spread, inventory, circuit breaker, etc.). If any limit is breached, the trade is blocked and an alert is sent.

#### Dry-Run Mode

`ArbBot` supports a strict dry-run flag:

```python
self.dry_run = config.get("dry_run", True)
...
if self.dry_run:
    logging.info(
        "DRY RUN | Would trade: %s %s size=%.4f spread=%.1fbps expected_pnl=$%.2f",
        pair,
        signal.direction.value,
        signal.size,
        signal.spread_bps,
        signal.expected_net_pnl,
    )
    return  # no Executor.execute()
```

For Week 5, you typically:

- use `--mode double_limit` (observation-only micro-arb),
- or `--mode simulation`/`paper` with `dry_run=True` to exercise the full state machine without real orders.

#### Kill Switch (File + Telegram)

Kill switch is a **shared file** in your OS temp directory:

```python
from pathlib import Path
import tempfile

KILL_SWITCH_FILE = str(Path(tempfile.gettempdir()) / "arb_bot_kill")
```

All main loops (`ArbBot.run`, `demo_double_limit.main`) do:

```python
if is_kill_switch_active():
    # pause: no new trades, but process + Telegram bot stay alive
```

The **Telegram bot** (`src/telegram_bot.py`) gives you remote control:

- `/kill` → creates `arb_bot_kill` → bots pause.
- `/resume` → deletes `arb_bot_kill` → bots resume.
- `/status` → replies with current kill-switch status.

Environment variables:

```env
TELEGRAM_BOT_TOKEN=123456:ABC...   # from BotFather
TELEGRAM_CHAT_ID=617012126        # your chat ID
TELEGRAM_POLL_SEC=1.0             # optional, default 2.0
```

The entrypoint (`scripts/arb_bot.py`) starts a shared `TelegramBot` for all modes and stops it on shutdown.

---

### Monitoring & Alerts

**Structured logging** (files + stdout):

- `scripts/arb_bot.py` → `logs/bot_YYYYMMDD.log`
- `scripts/demo_double_limit.py` → `logs/double_limit_YYYYMMDD.log`

```python
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s |%(levelname)s |%(message)s",
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler(),
    ],
)
```

**Webhook alerts** (`src/executor/alerts.py`) are already integrated:

- Circuit breaker trips / resets.
- Execution failures + unwind status.
- Drawdown alerts.

`ArbBot` also sends custom alerts for:

- Bot start (`mode`, `dry_run`),
- Kill switch activated / cleared,
- Trade completed with realized net PnL,
- Absolute safety limit violations (e.g. daily loss).

To wire alerts to Slack/Telegram/etc., point `WEBHOOK_URLS` to your bridge endpoint in `.env`.

---

### How to Run Week 5 Dry Run

#### 1. Configure `.env`

Minimum required for Double Limit dry run:

```env
# Arbitrum + ODOS + MEXC
ALCHEMY_API_KEY=...
ARBITRUM_RPC_HTTPS=https://arb-mainnet.g.alchemy.com/v2/...
ARBITRUM_WALLET_ADDRESS=0x...
USDC_ADDRESS=0xaf88d065e77c8cC2239327C5EDb3A432268e5831

MEXC_API_KEY=...
MEXC_API_SECRET=...
MEXC_BASE_URL=https://api.mexc.com

# ODOS has no API key, just base URL in OdosClient

# Double Limit parameters
TRADE_SIZE_USD=5.0
MIN_SPREAD_PCT=0.0075
MIN_PROFIT_USD=0.001
MAX_SLIPPAGE_PCT=0.5

# Optional: Telegram control
TELEGRAM_BOT_TOKEN=...
TELEGRAM_CHAT_ID=617012126
```

#### 2. Verify costs and token universe

**Cost verification** (recommended first):

```bash
python scripts/verify_all_costs.py
```

This verifies:
- Gas costs on Arbitrum (compares configured vs. actual),
- Bridge fees from MEXC (fetches actual withdrawal fees),
- LP fees by token (from configuration),
- Total cost estimation per trade.

**Token verification**:

```bash
python scripts/verify_tokens.py
```

This prints a **TOKEN VERIFICATION REPORT** and a JSON **CONFIG PATCH FOR FAILED TOKENS**. Week 5 already applied the patch for known failures (AAVE, CVX, FXS, YFI, LDO, etc.).

**Note**: Ensure your MEXC API key has:
- Correct `MEXC_API_KEY` and `MEXC_API_SECRET` in `.env` (whitespace is automatically stripped),
- "Withdrawal" permission enabled (not just "View deposit/withdrawal details"),
- IP address matches bound IP (if IP binding is enabled).

#### 3. Start Double Limit dry run

Use the unified entrypoint:

```bash
# Default trade size ($5.0 from TRADE_SIZE_USD env var or config)
python scripts/arb_bot.py --mode double_limit

# Custom trade size ($10.0)
python scripts/arb_bot.py --mode double_limit --trade-size 10.0

# Or use $5.0 explicitly
python scripts/arb_bot.py --mode double_limit --trade-size 5.0
```

**Trade size options**:
- `--trade-size 5.0` — $5 USD per trade (default, good for micro-arb testing)
- `--trade-size 10.0` — $10 USD per trade (larger positions, higher capital requirements)

If `--trade-size` is not specified, the bot uses `TRADE_SIZE_USD` from `.env` or defaults to `5.0`.

What this does:

- Starts structured logging and metrics.
- Starts the Telegram bot (if configured).
- Delegates to `scripts/demo_double_limit.py`:
  - Calls `DoubleLimitArbitrageEngine.evaluate_opportunity()` for each token.
  - Logs:
    - MEXC bid/ask,
    - ODOS price,
    - gross spread,
    - **net** profit after fees + gas + bridge amortization,
    - whether the opportunity is `EXECUTABLE` under your thresholds.
- **No real orders** are sent in this mode.

Let this run for **≥30 minutes** and keep `logs/double_limit_YYYYMMDD.log` as your Week‑5 dry‑run artifact.

#### 4. Optional: CEX/DEX arb bot dry run

To exercise the Week‑4 CEX/DEX engine with all safety gates:

```bash
python scripts/arb_bot.py --mode simulation    # or --mode paper
```

With `dry_run=True` (default), you’ll see:

```text
DRY RUN | Would trade: ETH/USDT buy_cex_sell_dex size=... spread=...bps expected_pnl=$...
```

covering:

- signal generation,
- scoring + priority queue,
- executor state machine and recovery (simulated),
- safety_check(),
- circuit breaker + webhook/Telegram alerts.

---

### Conceptual vs. Internship Baseline

Compared to a “basic” internship-style arb loop (single Uniswap V2 swap + MEXC/Binance market order with taker fees and public RPC), the Week‑5 framework pushes toward a **professional micro‑arbitrage architecture**:

- **Zero taker fees** on the CEX path (post‑only MEXC limit orders when real execution is enabled).
- **Aggregator-based DEX pricing** via ODOS instead of raw pool math.
- **Amortized fixed costs** via `CapitalManager` and bridge thresholding (bridge fee: $0.05 USDT per withdrawal, amortized over 5+ trades).
- **Strict safety limits** and kill switch, integrated at the execution boundary.
- **Observability**: structured logs, metrics, webhooks, and Telegram control.
- **Cost verification**: Automated scripts verify gas costs, bridge fees, and LP fees match actual market conditions.

**Recent updates**:
- Fixed MEXC API signature generation (handles GET requests correctly, strips whitespace from API keys).
- Updated bridge cost model: `bridge_fixed_cost_usd` set to $0.05 (actual MEXC withdrawal fee) instead of $0.32.
- Improved network matching: bridge verification now handles MEXC network names with parentheses (e.g., "Arbitrum One(ARB)").

The current codebase implements the **core building blocks** for this architecture in dry‑run / observation mode, so you can validate economics and safety before ever placing a real trade.

</details>
